<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<link href="https://mck.is/feed.xml" rel="self" type="application/atom+xml"/>
<link href="https://mck.is/" rel="alternate" type="text/html" hreflang="en"/>
<updated>2022-03-04T00:00:00Z</updated>
<id>https://mck.is/feed.xml</id>
<title type="html">James McKeeâ€™s Blog</title>
<subtitle>
My personal blog, where I ramble about whatever I'm currently interested in.
</subtitle>
<author>
<name>James McKee</name>
</author>
<entry>
<title type="html">Blog post for CSC1028</title>
<link href="https://mck.is/CSC1028/index.html" rel="alternate" type="text/html" title="Blog post for CSC1028"/>
<published>2022-03-04T00:00:00Z</published>
<updated>2022-03-04T00:00:00Z</updated>
<id>https://mck.is/CSC1028/index.html</id>
<content type="html" xml:base="https://mck.is/CSC1028/index.html">
&#60;h1 id=&#34;url-understanding-tool&#34;&#62; URL Understanding Tool&#60;/h1&#62;
&#60;p&#62;This project was created over the course of 7 weeks for my CSC1028 module, and although it is not a fully complete project, it provides a great framework for future work.&#60;/p&#62;

&#60;h3 id=&#34;aims-of-the-project&#34;&#62; Aims of the project&#60;/h3&#62;
&#60;p&#62;This project aims to be a tool for cybersecurity or power users to provide as much relevant metadata on a given URL as possible. Although there are only currently a few sources of data, the application is set up to be as easy as possible to add sources to.&#60;/p&#62;

&#60;p&#62;The project has 3 main parts:&#60;/p&#62;

&#60;h2 id=&#34;http-apis&#34;&#62; HTTP APIs&#60;/h2&#62;
&#60;p&#62;&#60;a href=&#34;https://github.com/James-McK/CSC1028APIs&#34;&#62;GitHub&#60;/a&#62;  &#60;br/&#62;
The main component of this project is a set of HTTP APIs that can be queried for information on a URL/IP address to provide information from various sources, from local databases to external APIs.  The current data sources are:&#60;ul&#62;
 	&#60;li&#62;A local MongoDB database containing data from Project Sonar&#60;/li&#62;
 	&#60;li&#62;A local MongoDB database containing data on phishing/malware URLs from &#60;a href=&#34;https://phishtank.org/&#34;&#62;Phishtank&#60;/a&#62;, &#60;a href=&#34;https://openphish.com/&#34;&#62;OpenPhish&#60;/a&#62;, &#60;a href=&#34;https://urlhaus.abuse.ch/&#34;&#62;URLHaus&#60;/a&#62; and &#60;a href=&#34;https://malwarediscoverer.com/&#34;&#62;MalwareDiscoverer&#60;/a&#62;.&#60;/li&#62;
 	&#60;li&#62;Earliest page/hostname archive date, from &#60;a href=&#34;https://archive.org&#34;&#62;https://archive.org&#60;/a&#62;.&#60;/li&#62;
 	&#60;li&#62;&#60;a href=&#34;https://www.similarweb.com/&#34;&#62;Similarweb&#60;/a&#62; global website rank&#60;/li&#62;
 	&#60;li&#62;IP Geolocation data (Currently from &#60;a href=&#34;https://ip-api.com/&#34;&#62;https://ip-api.com/&#60;/a&#62;, could probably be improved - this section did not have much thought put into it, and was mostly done as a proof of concept)&#60;/li&#62;
&#60;/ul&#62;

&#60;/p&#62;

&#60;p&#62;Several of these can also be queried via the command line, i.e. &#60;code&#62;node queryArchiveDate.js example.com&#60;/code&#62;&#60;/p&#62;

&#60;p&#62;For more information on dealing with Project Sonar&#39;s data, see &#60;a href=&#34;https://mck.is/project-sonar/&#34;&#62;my how-to guide&#60;/a&#62;, but in summary, the data is stored in a local MongoDB database which, when full, can fill up to 60gb. We then use &#60;a href=&#34;https://docs.mongodb.com/manual/core/index-text/&#34;&#62;text indexes&#60;/a&#62; to allow &#60;em&#62;extremely&#60;/em&#62; performant queries to be made.&#60;/p&#62;

&#60;p&#62;Note on Project Sonar&#39;s data: 6 days after I wrote my how-to guide, &#60;a href=&#34;https://www.rapid7.com/blog/post/2022/02/10/evolving-how-we-share-rapid7-research-data-2/&#34;&#62;Rapid7 switched to requiring you to apply&#60;/a&#62; to access Project Sonar&#39;s data. Except now, a few weeks later, it no longer requires an account again, and this time I cannot find any blog post etc. mentioning this change back, so I do not know if this is a permanent or temporary change.&#60;/p&#62;

&#60;h3 id=&#34;retrieving-data&#34;&#62; Retrieving data&#60;/h3&#62;
&#60;p&#62;To retrieve the data used for the above HTTP APIs, some of the modules send a request to an external API, while some query a local MongoDB database. To fetch the data used to fill up the MongoDB database, there exists two programs: One for parsing and inserting Project Sonar&#39;s data, and one for fetching, parsing and inserting malware/phishing data.&#60;/p&#62;

&#60;h3 id=&#34;creating-the-http-apis&#34;&#62; Creating the HTTP APIs&#60;/h3&#62;
&#60;p&#62;To create and manage the HTTP APIs, there is a single program (&#60;code&#62;createAllAPI.js&#60;/code&#62;) that opens up all the APIs when run (Ports 10130 to 10135 by default). This program does almost nothing itself, and imports functionality from other modules to create the APIs (Notably &#60;code&#62;createHTTPServer.js&#60;/code&#62;, which will take any function and open up an API for it on the given port.). This approach allows new APIs to be added with ease, and allows you to manage which modules are started.&#60;/p&#62;

&#60;h3 id=&#34;running/developing-the-application&#34;&#62; Running/developing the application&#60;/h3&#62;
&#60;p&#62;For developing any of this project, you&#39;ll need a few things set up and installed. I&#39;d recommend following the setup process I used in &#60;a href=&#34;https://mck.is/project-sonar/#setup&#34;&#62;my how-to guide&#60;/a&#62;. You&#39;ll also want to install the dependancies listed in &#60;code&#62;package.json&#60;/code&#62; with &#60;code&#62;npm install &#38;#60;package_name&#38;#62;&#60;/code&#62;. To actually get the data, you&#39;ll first want to run &#60;code&#62;./fetch/fetchMalwarePhishingData.js&#60;/code&#62; and &#60;code&#62;./fetch/fetchMalwarePhishingData.js&#60;/code&#62; (Assuming you&#39;ve downloaded Project Sonar&#39;s data in a similar way as I did in my &#60;a href=&#34;https://mck.is/project-sonar/#parsing-a-local-copy-of-project-sonar&#34;&#62;how-to guide&#60;/a&#62;).  &#60;br/&#62;
You can then run &#60;code&#62;node ./create/createAllAPI.js&#60;/code&#62; to start the APIs.&#60;/p&#62;

&#60;h2 id=&#34;electron-app&#34;&#62; Electron App&#60;/h2&#62;
&#60;p&#62;&#60;img src=&#34;ElectronUI2.png&#34; alt=&#34;Electron app UI&#34; loading=&#34;lazy&#34; /&#62; &#60;a href=&#34;https://github.com/James-McK/CSC1028ElectronApp&#34;&#62;GitHub&#60;/a&#62;&#60;/p&#62;

&#60;p&#62;The electron app provides a user-friendly interface allowing the user to make queries regarding any URL, and displays the data to the user in a better format than the entirely raw JSON, however further steps should be taken as the current presentation is still not easily readable.&#60;/p&#62;

&#60;p&#62;Since it is built with electron, the page is little more than a HTML page with some javascript behind it! As a result, all this app has to do is query the back-end HTTP APIs and display the result to the user!&#60;/p&#62;

&#60;h3 id=&#34;running-the-application&#34;&#62; Running the application&#60;/h3&#62;
&#60;p&#62;Assuming you&#39;ve followed the steps above for running/developing the central node.js app (Which you should have done, as this electron app isn&#39;t too useful without it), not much more is required to run the electron app. After opening the folder, you&#39;ll need to run &#60;code&#62;npm install --save-dev electron&#60;/code&#62; to install everything required for electron. You can then run &#60;code&#62;npm start&#60;/code&#62; to start the app.  &#60;br/&#62;
You might also want to look at &#60;a href=&#34;https://www.electronjs.org/docs/latest/tutorial/quick-start/&#34;&#62;https://www.electronjs.org/docs/latest/tutorial/quick-start/&#60;/a&#62; for an introduction to Electron.&#60;/p&#62;

&#60;h2 id=&#34;browser-addon&#34;&#62; Browser Addon&#60;/h2&#62;
&#60;p&#62;&#60;img src=&#34;BasicAddon.png&#34; alt=&#34;Basic Addon UI&#34; loading=&#34;lazy&#34; /&#62; &#60;a href=&#34;https://github.com/James-McK/CSC1028FFAddon&#34;&#62;GitHub&#60;/a&#62;&#60;/p&#62;

&#60;p&#62;The browser addon is extremely similar to the electron app, providing a user-friendly front end to the data, built with HTML and javascript. As it is integrated into the browser, it can automatically fetch and cache data as the user navigates the web.  &#60;br/&#62;
Note: The addon currently only supports Firefox, however it could be ported to support Chromium-based browsers extremely easily, as both share an extremely similar base API, with only a few functions being located in different namespaces, but providing the same results. (See &#60;a href=&#34;https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/Chrome_incompatibilities&#34;&#62;Chrome incompatibilities&#60;/a&#62; on MDN for details)&#60;/p&#62;

&#60;p&#62;The addon&#39;s UI is also currently lacking as I chose to shift focus away from it, as I decided the Electron UI was more important initially. However, since both are based on HTML and javascript, and the Electron app was built upon the framework of the browser addon, the updates for the Electron app should be able to be ported without too much effort.&#60;/p&#62;

&#60;h3 id=&#34;installing-the-addon&#34;&#62; Installing the addon&#60;/h3&#62;
&#60;p&#62;(Currently Firefox-only)  &#60;br/&#62;
Installing the addon is thankfully easy. Navigate to &#60;code&#62;about:debugging&#60;/code&#62; and click on the &#34;This Firefox&#34; tab. Click on &#34;Load Temporary Add-on...&#34; and navigate to the folder containing the addon files. Click on any of the files (e.g. &#60;code&#62;manifest.json&#60;/code&#62;) and load it. The addon is now loaded! Whenever you update your code and save it, you just need to click the &#34;Reload&#34; button that appears.  &#60;br/&#62;
I&#39;d also reccommend looking at &#60;a href=&#34;https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions&#34;&#62;MDN&#60;/a&#62; for excellent doccumentation of the WebExtension APIs.&#60;/p&#62;

&#60;p&#62;&#60;img src=&#34;LoadingAddon.png&#34; alt=&#34;Loading the addon&#34; loading=&#34;lazy&#34; /&#62;&#60;/p&#62;

&#60;h2 id=&#34;improvements-and-vision&#34;&#62; Improvements and vision&#60;/h2&#62;
&#60;p&#62;The project in its current state is nowhere near complete, but serves as a foundation to build further upon.&#60;/p&#62;

&#60;p&#62;There are many possible new data sources that could be integrated into the project, for example:&#60;ul&#62;
 	&#60;li&#62;Crowdsourced datasets, eg Trustpilot and other user-driven sources of metadata&#60;/li&#62;
 	&#60;li&#62;What tech stack companies are using, and alert the user to suspicious activity if a different result is actually found, using information from &#60;a href=&#34;https://stackshare.io&#34;&#62;https://stackshare.io&#60;/a&#62;&#60;/li&#62;
 	&#60;li&#62;Further integration with archives, e.g. thumbnails of pages from the &#60;a href=&#34;https://web.archive.org/&#34;&#62;Wayback Machine&#60;/a&#62; - If a webpage has only existed for a few days its chance of being malware or a phishing attack are higher&#60;/li&#62;
 	&#60;li&#62;Data from &#60;a href=&#34;https://commoncrawl.org/&#34;&#62;Common Crawl&#60;/a&#62; to find sites that point to a given page (They were having &#60;a href=&#34;https://groups.google.com/g/common-crawl/c/kEHzXZNu5To&#34;&#62;issues with 503 errors&#60;/a&#62; when I last looked into integrating this, although it appears to have been fixed since.)&#60;/li&#62;
 	&#60;li&#62;Possibly other sources of data like Mozilla Observatory or Google Lighthouse.&#60;/li&#62;
 	&#60;li&#62;General improvements to the user experience.&#60;/li&#62;
&#60;/ul&#62;

  And many other possible sources of interesting metadata!&#60;/p&#62;


</content>
<author>
<name>James McKee</name>
</author>
<category term="nodejs"/>
<category term="project sonar"/>
<category term="programming"/>
<summary type="html">
A summary of the project
</summary>
</entry>

<entry>
<title type="html">How to deal with Project Sonar's data</title>
<link href="https://mck.is/project-sonar/index.html" rel="alternate" type="text/html" title="How to deal with Project Sonar's data"/>
<published>2022-02-01T00:00:00Z</published>
<updated>2022-03-04T00:00:00Z</updated>
<id>https://mck.is/project-sonar/index.html</id>
<content type="html" xml:base="https://mck.is/project-sonar/index.html">
&#60;h2 id=&#34;what-is-project-sonar?&#34;&#62; What is Project Sonar?&#60;/h2&#62;
&#60;p&#62;&#60;a href=&#34;https://opendata.rapid7.com/&#34;&#62;Project Sonar&#60;/a&#62; is a data collection project containing information from scans across the internet: DNS records, SSL Certificates, and also scans of many commonly used ports with TCP/UDP.&#60;/p&#62;

&#60;p&#62;Update: 6 days after this guide was originally posted, &#60;a href=&#34;https://www.rapid7.com/blog/post/2022/02/10/evolving-how-we-share-rapid7-research-data-2/&#34;&#62;Rapid7 switched to requiring you to apply&#60;/a&#62; to access Project Sonar&#39;s data. Except now, a few weeks later (01/03/2022), it no longer requires an account again, and this time I cannot find any blog post etc. mentioning this change back, so I do not know if this is a permenant or temporary change.&#60;/p&#62;

&#60;h3 id=&#34;why-should-you-use-it?&#34;&#62; Why should you use it?&#60;/h3&#62;
&#60;p&#62;Project Sonar&#39;s forward DNS data can be used as a reverse DNS lookup (Finding a list of domains that point to a given IP address) more reliably than the standard method (&#60;a href=&#34;https://www.cloudflare.com/learning/dns/dns-records/dns-ptr-record/&#34;&#62;PTR Records&#60;/a&#62;).&#60;/p&#62;

&#60;p&#62;It can also be used for subdomain enumeration (Finding subdomains under the given domain), which can reveal web applications and other services are publicly exposed to the Internet.&#60;/p&#62;

&#60;p&#62;The port scans can also be used to guess at what software a server is running and publicly exposed.&#60;/p&#62;

&#60;h2 id=&#34;project-sonar&#39;s-data&#34;&#62; Project Sonar&#39;s data&#60;/h2&#62;
&#60;p&#62;I&#39;ll also explain a bit about what data Project Sonar contains:&#60;/p&#62;

&#60;h4 id=&#34;foreward-dns-(fdns)&#34;&#62; Foreward DNS (FDNS)&#60;/h4&#62;
&#60;p&#62;Contains data from the &#60;a href=&#34;https://en.wikipedia.org/wiki/Domain_Name_System&#34;&#62;Domain Name System&#60;/a&#62; (DNS), used to get from a &#60;a href=&#34;https://en.wikipedia.org/wiki/Hostname&#34;&#62;hostname&#60;/a&#62; like &#34;example.com&#34; to an IP address like &#60;code&#62;93.184.216.34&#60;/code&#62; (A records for an IPv4 address, AAAA record for an IPv6 address, or a CNAME rerecord, which points to another hostname). It also stores information like where an email should be sent to and what to do with an email if it is suspected of being spam (See &#60;a href=&#34;https://www.gov.uk/government/publications/email-security-standards/domainkeys-identified-mail-dkim&#34;&#62;DKIM&#60;/a&#62; for more on that). For more on DNS records, &#60;a href=&#34;https://www.cloudflare.com/en-gb/learning/dns/dns-records/&#34;&#62;Cloudflare&#60;/a&#62; has some good doccumentation.&#60;/p&#62;

&#60;h4 id=&#34;reverse-dns-(rdns)&#34;&#62; Reverse DNS (RDNS)&#60;/h4&#62;
&#60;p&#62;This dataset contains the results of PTR Lookups, which is essentially the reverse of A records mention above. However PTR lookups are not perfectly reliable, and it is generally recommended to use A records to resolve IP addresses to a hostname instead of PTR Lookups.&#60;/p&#62;

&#60;h4 id=&#34;http-get-responses&#34;&#62; HTTP GET Responses&#60;/h4&#62;
&#60;p&#62;This dayaset contains the results of &#60;a href=&#34;https://en.wikipedia.org/wiki/GET_request&#34;&#62;HTTP GET requests&#60;/a&#62; against ports commonly used for HTTP (Generally port 80 is used for the majority of HTTP requests).&#60;/p&#62;

&#60;h4 id=&#34;https-get-responses&#34;&#62; HTTPS GET Responses&#60;/h4&#62;
&#60;p&#62;Same as above, except against ports commonly used for &#60;a href=&#34;https://en.wikipedia.org/wiki/HTTPS&#34;&#62;HTTPS&#60;/a&#62;. (Port 443 is the most commonly used for HTTPS)&#60;/p&#62;

&#60;h4 id=&#34;tcp-scans&#34;&#62; TCP Scans&#60;/h4&#62;
&#60;p&#62;This dataset contains responses from many commonly used &#60;a href=&#34;https://en.wikipedia.org/wiki/Transmission_Control_Protocol&#34;&#62;TCP&#60;/a&#62; ports, which can be used to check what services a server may be running, or could be vulnerable. To see what a given port is used for, check &#60;a href=&#34;https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml&#34;&#62;https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml&#60;/a&#62; (&#60;a href=&#34;https://en.wikipedia.org/wiki/Internet_Assigned_Numbers_Authority&#34;&#62;IANA&#60;/a&#62; are in charge of managing what ports are &#34;officially&#34; used for to avoid multiple services using the same port)&#60;/p&#62;

&#60;h4 id=&#34;udp-scans&#34;&#62; UDP Scans&#60;/h4&#62;
&#60;p&#62;Same as the above TCP scans, but with &#60;a href=&#34;https://en.wikipedia.org/wiki/User_Datagram_Protocol&#34;&#62;UDP&#60;/a&#62;.&#60;/p&#62;

&#60;h4 id=&#34;ssl-certificates-&#38;-more-ssl-certificates-(non-443)&#34;&#62; SSL Certificates &#38; More SSL Certificates (non-443)&#60;/h4&#62;
&#60;p&#62;Contains data on certificates used for secuting HTTPS connections.&#60;/p&#62;

&#60;h2 id=&#34;setup&#34;&#62; Setup&#60;/h2&#62;
&#60;p&#62;To start, you&#39;re going to want to be using an IDE - I&#39;d reccommend &#60;a href=&#34;https://code.visualstudio.com/&#34;&#62;Visual Studio Code&#60;/a&#62;. This guide is written assuming you&#39;re using VS Code, but everything will still work if you choose a different IDE. It&#39;s also assuming you&#39;ve not used Node.js before - if you have, you might want to skip to &#60;a href=&#34;#start-programming&#34;&#62;Start Programming&#60;/a&#62;. Finally, all the code for this guide is also &#60;a href=&#34;https://github.com/James-McK/ProjectSonarTutorial&#34;&#62;up on GitHub&#60;/a&#62;!&#60;/p&#62;

&#60;p&#62;Start by making a new folder to hold your project - I called mine ProjectSonarTutorial - and open it in VS Code. We&#39;re going to need to install Node.js too - a convenient way to do so is using a version manager like &#60;a href=&#34;https://github.com/nvm-sh/nvm&#34;&#62;nvm&#60;/a&#62; for Linux and MacOS, or &#60;a href=&#34;https://github.com/coreybutler/nvm-windows&#34;&#62;nvm-windows&#60;/a&#62; for Windows.&#60;/p&#62;

&#60;p&#62;Once you have one of these installed (Note: On windows, you may have to restart your computer to use nvm), we can install install Node.js. Open up a terminal as administrator (Or run the commands with &#60;code&#62;sudo&#60;/code&#62; on linux/mac) and run &#60;code&#62;nvm install 16&#60;/code&#62;. This will install the latest version of Node 16, currently 16.13.2 (We&#39;re using Node 16 instead of the newer 17 as some packages are currently incompatible with it), then run &#60;code&#62;nvm use 16.13.2&#60;/code&#62;. Now we have node.js installed and set up!&#60;/p&#62;

&#60;p&#62;We&#39;re also going to be using MongoDB - I used a local installation for this tutorial. To install it, follow the instructions over at &#60;a href=&#34;https://docs.mongodb.com/manual/installation/&#34;&#62;https://docs.mongodb.com/manual/installation/&#60;/a&#62;. MongoDB compass might be installed along side it, but if not, I&#39;d reccommend installing it too - it&#39;s a useful tool for inspecting your databases.&#60;/p&#62;

&#60;p&#62;Returning to VS Code, we can open up its built in terminal with &#60;code&#62;ctrl + &#38;#39;&#60;/code&#62;. We&#39;re going to need a few external packages later, so we might as well install them now. First up, we&#39;ll generate the package.json file (Where information like what packages your program depends on  is stored), by running &#60;code&#62;npm init&#60;/code&#62;. &#60;code&#62;npm&#60;/code&#62; stands for Node Package Manager, and is how you can install external packages (Like the MongoDB Node.js Driver) to use in your program. &#60;code&#62;npm init&#60;/code&#62;&#39;s defaults are probably good enough, however you can change them if you wish. Next up, open the &#60;code&#62;package.json&#60;/code&#62; file that was created, and add the line &#60;code&#62;&#38;#34;type&#38;#34;: &#38;#34;module&#38;#34;,&#60;/code&#62; below the description line - This marks our program as using the newer &#60;code&#62;import ... from ...&#60;/code&#62; syntax instead of the older &#60;code&#62;var ... = require(...)&#60;/code&#62; syntax. Be aware that some tutorials still make use of the old syntax, however. Finally, run &#60;code&#62;npm install mongodb&#60;/code&#62; and &#60;code&#62;npm install tldts-experimental&#60;/code&#62; to install the packages that we need.&#60;/p&#62;

&#60;h2 id=&#34;start-programming&#34;&#62; Start programming&#60;/h2&#62;
&#60;p&#62;Now we can begin to get to the interesting stuff: create a file called &#60;code&#62;fetchData.js&#60;/code&#62;. At the top of it, we can add:
&#60;pre&#62;&#60;code&#62;import { MongoClient } from &#38;#34;mongodb&#38;#34;;
import { parse as tldParse } from &#38;#34;tldts-experimental&#38;#34;;
import zlib from &#38;#34;zlib&#38;#34;;
import fs from &#38;#34;fs&#38;#34;;
import { get as getHttps } from &#38;#34;https&#38;#34;;
import readline from &#38;#34;readline&#38;#34;; &#60;/code&#62;&#60;/pre&#62;This imports what we need from the two packages we just installed, along with what we&#39;ll need from node&#39;s core modules.&#60;/p&#62;

&#60;p&#62;We&#39;ll then add our main function:
&#60;pre&#62;&#60;code&#62;/**
 * Main function
 */
async function main() {
	// Content of main function goes here
}

// Run the main function
main().catch(console.error); &#60;/code&#62;&#60;/pre&#62;&#60;/p&#62;

&#60;p&#62;To make sure everything is up and running, add the typical &#34;Hello World&#34; to the main function with &#60;code&#62;console.log(&#38;#34;Hello World!&#38;#34;);&#60;/code&#62;. To run the program, go to the terminal and run &#60;code&#62;node fetchData.js&#60;/code&#62; - Hopefully you should be greeted with &#34;Hello World!&#34; being logged.&#60;/p&#62;

&#60;p&#62;Next up we&#39;ll connect to MongoDB. Since we&#39;re using a local database, the connection URI should be as simple as &#60;code&#62;&#38;#34;mongodb://localhost:27017&#38;#34;&#60;/code&#62;. Then we can create a new MongoClient, and pass our connection string to its constructor. Then we can open the connection with &#60;code&#62;await client.connect();&#60;/code&#62; To make sure everything is working, we can print a list of all databases. Let&#39;s make a function for it!&#60;/p&#62;


&#60;p&#62;&#60;pre&#62;&#60;code&#62;async function listDatabases(client) {
    let dbList = await client.db().admin().listDatabases();
 
    console.log(&#38;#34;Databases:&#38;#34;);
    dbList.databases.forEach(db =&#38;#62; console.log(` - ${db.name}`));
}; &#60;/code&#62;&#60;/pre&#62;&#60;/p&#62;

&#60;p&#62;Call the new listDatabases function from within our main function, and pass it the MongoClient we created, after opening the client&#39;s connection. Running our code so far (with &#60;code&#62;node fetchData.js&#60;/code&#62;) we should get something like this: &#60;img src=&#34;ListDatabases.png&#34; alt=&#34;List of databases&#34; loading=&#34;lazy&#34; /&#62;&#60;/p&#62;

&#60;p&#62;Your code so far should be similar to
&#60;pre&#62;&#60;code&#62;import { MongoClient } from &#38;#34;mongodb&#38;#34;;
import { parse as tldParse } from &#38;#34;tldts-experimental&#38;#34;;
import zlib from &#38;#34;zlib&#38;#34;;
import fs from &#38;#34;fs&#38;#34;;
import { get as getHttps } from &#38;#34;https&#38;#34;;
import readline from &#38;#34;readline&#38;#34;;

/**
 * Main function
 */
async function main() {
	// Database is currently hosted on same machine
	const uri = &#38;#34;mongodb://localhost:27017&#38;#34;;
	const client = new MongoClient(uri);

	try {
		// Connect to MongoDB
		await client.connect();
		
		// List databases
		await listDatabases(client);
	} catch (e) {
		console.error(e);
	}
}

async function listDatabases(client) {
	let dbList = await client.db().admin().listDatabases();

	console.log(&#38;#34;Databases:&#38;#34;);
	dbList.databases.forEach((db) =&#38;#62; console.log(` - ${db.name}`));
}

// Run the main function
main().catch(console.error); &#60;/code&#62;&#60;/pre&#62;&#60;/p&#62;

&#60;p&#62;You might have have noticed that the program still appears to be running, and you can no longer type in the terminal. You can press &#60;code&#62;Ctrl + c&#60;/code&#62; when focused on the terminal to stop the currently running program at any time.&#60;/p&#62;

&#60;p&#62;Next, we need to fetch the data. There are 2 options for this:&#60;ul&#62;
 	&#60;li&#62;Use a local copy of the file that we can parse&#60;/li&#62;
 	&#60;li&#62;Stream the data from the web and parse it as we receive it&#60;/li&#62;
&#60;/ul&#62;

 Both options are shown in this tutorial (See &#60;a href=&#34;#parsing-a-local-copy-of-project-sonar&#34;&#62;Parsing a local copy of Project Sonar&#60;/a&#62; and &#60;a href=&#34;#fetching-and-parsing-an-online-version-of-project-sonar&#34;&#62;Fetching and parsing an online version of Project Sonar&#60;/a&#62;).&#60;/p&#62;

&#60;p&#62;I&#39;d probably reccommend using the local copy, as it does not depend on your internet connection&#39;s reliability, but it does require you to have the space to store the compressed file, in addition to the storage space required by the MongoDB database itself.&#60;/p&#62;

&#60;p&#62;Project Sonar&#39;s data can be found at &#60;a href=&#34;https://opendata.rapid7.com/sonar.fdns_v2/&#34;&#62;https://opendata.rapid7.com/sonar.fdns_v2/&#60;/a&#62;.  In this guide, I&#39;m going to be parsing the DNS A Records, so, we need the file ending in &#60;code&#62;-fdns_a.json.gz&#60;/code&#62;. Do note that the file is large (17gb) and be careful not to unzip it - uncompressed, it is over 200gb! &#60;/p&#62;

&#60;h2 id=&#34;parsing-a-local-copy-of-project-sonar&#34;&#62; Parsing a local copy of Project Sonar&#60;/h2&#62;
&#60;p&#62;Let&#39;s add a new function, &#60;code&#62;readFromFile&#60;/code&#62;.&#60;/p&#62;


&#60;p&#62;&#60;pre&#62;&#60;code&#62;async function readFromFile(client) {
	const sonarDataLocation = &#38;#34;fdns_a.json.gz&#38;#34;;
	let stream = fs.createReadStream(sonarDataLocation);
	parseSonar(client, stream);
} &#60;/code&#62;&#60;/pre&#62;&#60;/p&#62;

&#60;p&#62;&#60;code&#62;sonarDataLocation&#60;/code&#62; should be wherever you saved the data to - either a relative path, in the current case (&#60;code&#62;fdns_a.json&#60;/code&#62; is in the same folder as &#60;code&#62;fetchData.js&#60;/code&#62;), or an absolute path, like &#60;code&#62;C:\\Users\\James\\Downloads\\fdns_a.json.gz&#60;/code&#62;. We then create a &#60;a href=&#34;https://nodejs.org/api/stream.html#stream&#34;&#62;read stream&#60;/a&#62; - not the actual data itself - that we can later read through and parse. &#60;code&#62;fs&#60;/code&#62; is Node.js&#39;s filesystem module, allowing us to interact with local files. We then pass this stream, and the MongoClient passed into the function, to a function that does not yet exist - it&#39;s next for us to make.&#60;/p&#62;

&#60;p&#62;Finally, let&#39;s call this method from the main function with &#60;code&#62;readFromFile(client);&#60;/code&#62;&#60;/p&#62;

&#60;p&#62;Alternatively, if you don&#39;t want to have the file saved locally:&#60;/p&#62;

&#60;h2 id=&#34;fetching-and-parsing-an-online-version-of-project-sonar&#34;&#62; Fetching and parsing an online version of Project Sonar&#60;/h2&#62;
&#60;p&#62;This method is a bit more complicated, but means that we do not have to keep a copy saved on our machine, taking up space. It will require you to have a reliable internet connection, however.&#60;/p&#62;

&#60;p&#62;Let&#39;s add a new function, &#60;code&#62;readFromWeb&#60;/code&#62;.
&#60;pre&#62;&#60;code&#62;async function readFromWeb(client, url) {
	getHttps(url, function (res) {
		// Code here
	}).on(&#38;#34;error&#38;#34;, function (e) {
		console.error(e);
	});
} &#60;/code&#62;&#60;/pre&#62;This function calls the get method from node&#39;s https package that we imported earlier as &#60;code&#62;getHttps&#60;/code&#62;. It gets the result of this call as &#60;code&#62;res&#60;/code&#62;, currently does northing with it, and will log any errors. So what do we do with this result? First of all, we need to deal with redirects. &#60;a href=&#34;https://opendata.rapid7.com/sonar.fdns_v2/2022-01-28-1643328400-fdns_a.json.gz&#34;&#62;https://opendata.rapid7.com/sonar.fdns_v2/2022-01-28-1643328400-fdns_a.json.gz&#60;/a&#62;, The link on Project Sonar&#39;s site, actually redirects to backblaze, where the data is actually hosted, before allowing you to download it.&#60;/p&#62;

&#60;p&#62;Fortunately, we can check if we need to redirect based on the result&#39;s &#60;a href=&#34;https://httpstatuses.com/&#34;&#62;HTTP status code&#60;/a&#62;. If the status is 200, we&#39;re in the right place, and can return the result to be used elsewhere. If the status is 301 or 303, we should follow the redirect by calling the readFromWeb method again, with the new URL being passed in as an argument. I&#39;ve added the following code inside the above &#60;code&#62;getHttps&#60;/code&#62; call:
&#60;pre&#62;&#60;code&#62;if (res.statusCode === 200) {
	parseSonar(client, res);
} else if (res.statusCode === 301 || res.statusCode === 302) {
	// Recursively follow redirects, only a 200 will resolve.
	console.log(`Redirecting to: ${res.headers.location}`);
	readFromWeb(client, res.headers.location);
} else {
	console.log(`Download request failed, response status: ${res.statusCode} ${res.statusMessage}`);
} &#60;/code&#62;&#60;/pre&#62;This function gets a &#60;a href=&#34;https://nodejs.org/api/stream.html#stream&#34;&#62;read stream&#60;/a&#62; - not the actual data itself - that we can later read through and parse. We can then pass it to a function that does not yet exist (We&#39;ll add it shortly) along with the MongoClient this function was passed.&#60;/p&#62;

&#60;p&#62;Now we can return to our main method and add in something to call our new function
&#60;pre&#62;&#60;code&#62;const dataUrl = &#38;#34;https://opendata.rapid7.com/sonar.fdns_v2/2022-01-28-1643328400-fdns_a.json.gz&#38;#34;;
readFromWeb(client, dataUrl); &#60;/code&#62;&#60;/pre&#62;&#60;/p&#62;

&#60;p&#62;Note that if this doesn&#39;t work, make sure you have the latest link from &#60;a href=&#34;https://opendata.rapid7.com/sonar.fdns_v2/&#34;&#62;https://opendata.rapid7.com/sonar.fdns_v2/&#60;/a&#62;, as downloading older/newer versions requires an account.&#60;/p&#62;

&#60;h2 id=&#34;parsing-our-input&#34;&#62; Parsing our input&#60;/h2&#62;
&#60;p&#62;So now, using either of the above methods, we have a stream that will allow us to read in the project sonar data. Unfortunately, we still have two things to deal with before getting to anything useful: We have to get data out of the stream, and then we have to decompress the data we&#39;ve been given - it&#39;s currently still &#60;a href=&#34;https://en.wikipedia.org/wiki/Gzip&#34;&#62;gzipped&#60;/a&#62;.&#60;/p&#62;

&#60;p&#62;Luckily, we can deal with both of those problems pretty quickly! Let&#39;s create a new function:
&#60;pre&#62;&#60;code&#62;async function parseSonar(client, readstream) {
	// Pipe the response into gunzip to decompress
	let gunzip = zlib.createGunzip();

	let lineReader = readline.createInterface({
		input: readstream.pipe(gunzip),
	});
} &#60;/code&#62;&#60;/pre&#62;&#60;/p&#62;

&#60;p&#62;What we&#39;re doing here is:&#60;ul&#62;
 	&#60;li&#62;Creating a writable stream called &#60;code&#62;gunzip&#60;/code&#62; with &#60;code&#62;zlib&#60;/code&#62;, node.js&#39;s module for compression/decompression&#60;/li&#62;
 	&#60;li&#62;Piping our readstream of compressed Project Sonar data to this &#60;code&#62;gunzip&#60;/code&#62; object&#60;/li&#62;
 	&#60;li&#62;Taking the output of that, and using it as the input for a readline object, which allows us to parse the data one line at a time. (It also means we don&#39;t have to worry about buffers stopping mid-line and giving us all sorts of errors.)&#60;/li&#62;
&#60;/ul&#62;

&#60;/p&#62;

&#60;p&#62;Quite a lot for a few lines of code!  &#60;br/&#62;
Now, we still need to get our data out of this linereader. To do this, we can use the &#60;code&#62;&#38;#34;line&#38;#34;&#60;/code&#62; event that the linereader &#39;emits&#39; to let us know when we have a new line to parse, with:
&#60;pre&#62;&#60;code&#62;lineReader.on(&#38;#34;line&#38;#34;, (line) =&#38;#62; {
	// We&#38;#39;ll parse the line in here
}); &#60;/code&#62;&#60;/pre&#62;&#60;/p&#62;

&#60;p&#62;So we&#39;ve got a line of data - now what?  &#60;br/&#62;
The data is in JSON form, and luckily for us, we can simply use javascript&#39;s &#60;code&#62;JSON.parse()&#60;/code&#62; to parse it. Next up, we need to break the hostname (eg &#60;code&#62;subdomain.example.com/path&#60;/code&#62;) into it parts - we need just the &#60;code&#62;example&#60;/code&#62; bit (This is required for performance - I&#39;ll explain more once we get to that point). We can do this pretty easily by using the &#60;code&#62;tldts-experimental&#60;/code&#62; package&#39;s &#60;code&#62;parse&#60;/code&#62; function we imported earlier as &#60;code&#62;tldParse&#60;/code&#62;.&#60;/p&#62;

&#60;p&#62;First, we need to deal with the many records beginning with &#60;code&#62;*.&#60;/code&#62;. If we don&#39;t remove this from the start of the hostname, we cannot properly parse it. Next, let&#39;s parse it with &#60;code&#62;tldParse&#60;/code&#62; and log it, to make sure everything is working so far.&#60;/p&#62;


&#60;p&#62;&#60;pre&#62;&#60;code&#62;let lineJson = JSON.parse(line);
let hostname = lineJson.name;

if (hostname.substring(0, 2) === &#38;#34;*.&#38;#34;) hostname = hostname.substring(2);

let tldParsed = tldParse(hostname);

console.log(tldParsed); &#60;/code&#62;&#60;/pre&#62;&#60;/p&#62;

&#60;p&#62;You should now hopefully see lines of JSON being printed! We should probably remove that &#60;code&#62;console.log&#60;/code&#62; for now though - printing out every single line hurts our performance.  &#60;br/&#62;
Note that there are still a few invalid hostnames - Some beginning with &#60;code&#62;/&#60;/code&#62;, &#60;code&#62;-&#60;/code&#62; or &#60;code&#62;*&#60;/code&#62;. I don&#39;t know why these are here, but given that only around 0.2% of the results are invalid, it&#39;s probably safe enough to ignore them for now.&#60;/p&#62;

&#60;h2 id=&#34;mongodb&#34;&#62; MongoDB&#60;/h2&#62;
&#60;p&#62;Now we need to start thinking about MongoDB. Whilst MongoDB is fast, it is unfortunately not fast enough to get us a quick result from 1.7 billion items. To speed it up, we&#39;ll make use of &#60;a href=&#34;https://docs.mongodb.com/manual/core/index-text/&#34;&#62;text indexes&#60;/a&#62;.&#60;/p&#62;

&#60;p&#62;Back in our main function, let&#39;s add a line to create this text index.  
&#60;pre&#62;&#60;code&#62;await client.db(&#38;#34;test_db&#38;#34;).collection(&#38;#34;sonardata&#38;#34;).createIndex({ domainWithoutSuffix: &#38;#34;text&#38;#34; }); &#60;/code&#62;&#60;/pre&#62;You can call your database and collection whatever you want - this is just what I&#39;m using. We&#39;re using the domain without the suffix as our index, as that&#39;s what I&#39;m wanting to query later on. If, however, you wanted to query IP address, to find out which domains point to a given IP address, you&#39;d use it as your text index instead.&#60;/p&#62;

&#60;p&#62;We also don&#39;t want redundant data building up each time we run our program - let&#39;s add something to drop the collection each time the program is run. (We don&#39;t need to add anything to create the collection again - MongoDB does this automatically for us whenever we try to add data to it.)
&#60;pre&#62;&#60;code&#62;// Drop the collection containg Project Sonar data
try {
	await client.db(&#38;#34;test_db&#38;#34;).collection(&#38;#34;sonardata&#38;#34;).drop();
} catch {} &#60;/code&#62;&#60;/pre&#62;&#60;/p&#62;

&#60;p&#62;Nice! Now we can begin actually adding the data to MongoDB.  &#60;br/&#62;
Returning back to our &#60;code&#62;parseSonar&#60;/code&#62; function - items can be inserted in bulk to MongoDB to increase performance, up to 100k items - so let&#39;s do that. After we&#39;ve created the linereader, let&#39;s create an array and a counter to keep track of how many items we have.&#60;/p&#62;

&#60;p&#62;Now, after the JSON has been parsed, we can increment our counter and add whatever data we want to our buffer array. Then, when our counter is evenly divisible by 100,000, we can log how many lines have been parsed, send our data to be added to MongoDB, and clear our buffer array. Our parseSonar function should now look something like:
&#60;pre&#62;&#60;code&#62;async function parseSonar(client, readstream) {
	// Pipe the response into gunzip to decompress
	let gunzip = zlib.createGunzip();

	let lineReader = readline.createInterface({
		input: readstream.pipe(gunzip),
	});

	let arr = [];
	let count = 0;
	lineReader.on(&#38;#34;line&#38;#34;, (line) =&#38;#62; {
		let lineJson = JSON.parse(line);
		let hostname = lineJson.name;
		if (hostname.substring(0, 2) === &#38;#34;*.&#38;#34;) hostname = hostname.substring(2);

		let tldParsed = tldParse(hostname);

		if (tldParsed.domainWithoutSuffix) {
			count++;
			// What data you&#38;#39;re putting in the array depends on what you&#38;#39;re planning to do with it
			arr.push({
				domainWithoutSuffix: tldParsed.domainWithoutSuffix,
				publicSuffix: tldParsed.publicSuffix,
				subdomain: tldParsed.subdomain,
				name: lineJson.name,
				type: lineJson.type,
				value: lineJson.value,
			});
			
			if (count % 100000 === 0) {
				console.log(`${count} lines parsed`);
				createManyListings(client, arr, &#38;#34;sonardata&#38;#34;);
				arr = [];
			}
		}
	});
} &#60;/code&#62;&#60;/pre&#62;&#60;/p&#62;

&#60;p&#62;Nearly done now! We just need to add the &#60;code&#62;createManyListings&#60;/code&#62; function. Thankfully, it&#39;s pretty simple:
&#60;pre&#62;&#60;code&#62;async function createManyListings(client, newListing, collection, dbName = &#38;#34;test_db&#38;#34;) {
	client.db(dbName).collection(collection).insertMany(newListing, { ordered: false });
} &#60;/code&#62;&#60;/pre&#62;The only thing to note here is that we&#39;re telling MongoDB that our data is not/does not need to be ordered, helping increase our performance slightly. Running the program now will begin filling up our database with data. Unfortunately, this is still a slow process - We have about 1.7 billion lines to parse! Finally, you may also run into memory issues with NodeJS, as by default it can only use &#60;a href=&#34;https://www.the-data-wrangler.com/nodejs-memory-limits/&#34;&#62;up to 1.7gb of memory&#60;/a&#62;, and MongoDB cannot always keep up with the rate we are sending it data at (It&#39;s inconsistant). Since we only need our application to run for long enough to allow us to fetch all the data, we can take the quick and easy approach of just giving NodeJS more memory. We can do this by running &#60;code&#62;node --max-old-space-size=8000 fetchData.js&#60;/code&#62;.&#60;/p&#62;

&#60;h2 id=&#34;querying-mongodb&#34;&#62; Querying MongoDB&#60;/h2&#62;
&#60;p&#62;So, we have our data sitting in a collection in MongoDB. Now what?&#60;/p&#62;

&#60;p&#62;Create a new file called &#60;code&#62;queryData.js&#60;/code&#62;. We can follow the basic template of the previous file to get started:
&#60;pre&#62;&#60;code&#62;import { MongoClient } from &#38;#34;mongodb&#38;#34;;

/**
 * Main function
 */
async function main() {
	// Database is currently hosted on same machine
	const uri = &#38;#34;mongodb://localhost:27017&#38;#34;;
	const client = new MongoClient(uri);

	try {
		// Connect to the MongoDB cluster
		await client.connect();
		
		// Run query here
	} catch (e) {
		// Log any errors
		console.error(e);
	} finally {
		await client.close();
	}
}

// Run the main function
main().catch(console.error); &#60;/code&#62;&#60;/pre&#62;&#60;/p&#62;

&#60;p&#62;Now we need to come up with a query! As an example, I&#39;ll search for subdomains of rapid7.  &#60;br/&#62;
To actually query this, I&#39;ll use:
&#60;pre&#62;&#60;code&#62;let query = { $text: { $search: &#38;#34;rapid7&#38;#34; }, domainWithoutSuffix: &#38;#34;rapid7&#38;#34; };
await findMany(client, query, &#38;#34;sonardata&#38;#34;); &#60;/code&#62;&#60;/pre&#62;To explain what the query actually means:&#60;ul&#62;
 	&#60;li&#62;&#60;code&#62;$text: { $search: &#38;#34;rapid7&#38;#34; }&#60;/code&#62; is how we&#39;re able to make queries with a reasonable level of performance - It makes use of the text index we set up earlier, and matches with all  &#60;code&#62;domainWithoutSuffix&#60;/code&#62;s that &#60;strong&#62;contain&#60;/strong&#62; (&#60;em&#62;not&#60;/em&#62; match exactly) the given query.&#60;/li&#62;
 	&#60;li&#62;&#60;code&#62;domainWithoutSuffix: &#38;#34;rapid7&#38;#34;&#60;/code&#62; narrows that down further to only the exact matches.&#60;/li&#62;
&#60;/ul&#62;

&#60;/p&#62;

&#60;p&#62;We could continue to further narrow this down if we wanted (For more info, see &#60;a href=&#34;https://docs.mongodb.com/manual/tutorial/query-documents/&#34;&#62;https://docs.mongodb.com/manual/tutorial/query-documents/&#60;/a&#62;). First though, we need to add in the &#60;code&#62;findMany&#60;/code&#62; function that we&#39;re calling.&#60;/p&#62;


&#60;p&#62;&#60;pre&#62;&#60;code&#62;async function findMany(client, query, collection, db_name = &#38;#34;test_db&#38;#34;, maxResults = 500) {
	const cursor = client.db(db_name).collection(collection).find(query).limit(maxResults);

	const results = await cursor.toArray();

	if (results.length &#38;#62; 0) {
		console.log(&#38;#34;Found items:&#38;#34;);
		results.forEach((result, i) =&#38;#62; {
			console.log(result);
		});
	} else {
		console.log(&#38;#34;No results found with the given query!&#38;#34;);
	}
} &#60;/code&#62;&#60;/pre&#62;&#60;/p&#62;

&#60;p&#62;This function is fairly simple - all it does is fetch the results of the query to the given collection as an array, then if there are results, print them.&#60;/p&#62;

&#60;p&#62;And that&#39;s it! Now you&#39;re able to query Project Sonar&#39;s data! Although this guide only covered the DNS A records, the same principles apply to the port scans, SSL certificates, etc.&#60;/p&#62;

&#60;h2 id=&#34;final-note-on-compiling-to-executable&#34;&#62; Final note on compiling to executable&#60;/h2&#62;
&#60;p&#62;This won&#39;t be relevant to everybody, but as I encountered issues with it I&#39;m putting it here in the hope it will help somebody.&#60;/p&#62;

&#60;p&#62;&#60;code&#62;pkg&#60;/code&#62;, the most popular option for compiling NodeJS executables, still does not support the several-year old javascript ES6 modules (See &#60;a href=&#34;https://github.com/vercel/pkg/issues/1291&#34;&#62;this&#60;/a&#62; github issue and &#60;a href=&#34;https://github.com/vercel/pkg/pull/1323&#34;&#62;this&#60;/a&#62; pull request for updates), so we&#39;ll be using &#60;a href=&#34;https://github.com/nexe/nexe&#34;&#62;nexe&#60;/a&#62; instead. Unfortunately, the latest version of NodeJS that &#60;code&#62;nexe&#60;/code&#62; has pre-compiled is 14, and we need to be using version 16, so we&#39;ll need to compile it ourselves later. Don&#39;t worry, this isn&#39;t too difficult!&#60;/p&#62;

&#60;p&#62;Let&#39;s begin by installing &#60;code&#62;nexe&#60;/code&#62; with &#60;code&#62;npm i nexe -g&#60;/code&#62;. We&#39;ll then need to follow the instructions for building &#60;a href=&#34;https://github.com/nodejs/node/blob/v16.x/BUILDING.md&#34;&#62;here&#60;/a&#62;. (Use the section for Linux, Windows or MacOS depending on what you are using)&#60;/p&#62;

&#60;p&#62;We can select which file we want &#60;code&#62;nexe&#60;/code&#62; to build by running  then run &#60;code&#62;nexe --build&#60;/code&#62; to start building. (If you get an error, you probably don&#39;t have everything required installed. Look at the output of &#60;code&#62;nexe  --build --verbose&#60;/code&#62; to see what you&#39;re missing). This will probably take a while - on my laptop, it took half an hour, and fifteen minutes on my desktop. (To get an estimate of how long it&#39;ll take for you, see &#60;a href=&#34;https://openbenchmarking.org/test/pts/build-nodejs&#34;&#62;https://openbenchmarking.org/test/pts/build-nodejs&#60;/a&#62;.)&#60;/p&#62;

&#60;p&#62;Once that step has completed, we can finally build our application by running &#60;code&#62;nexe &#38;#60;filename&#38;#62; -b&#60;/code&#62;, and additionally can target other platforms by using &#60;code&#62;--target win&#60;/code&#62;, or &#60;code&#62;--target linux&#60;/code&#62;, etc. as additional arguments.&#60;/p&#62;


</content>
<author>
<name>James McKee</name>
</author>
<category term="nodejs"/>
<category term="project sonar"/>
<category term="programming"/>
<summary type="html">
From the beginning
</summary>
</entry>

<entry>
<title type="html">I love FTL: Faster Than Light</title>
<link href="https://mck.is/blog/2022/i-love-ftl/index.html" rel="alternate" type="text/html" title="I love FTL: Faster Than Light"/>
<published>2022-01-29T23:23:00Z</published>
<updated>2022-01-29T23:23:00Z</updated>
<id>https://mck.is/blog/2022/i-love-ftl/index.html</id>
<content type="html" xml:base="https://mck.is/blog/2022/i-love-ftl/index.html">
&#60;p&#62;This blog post was written to be the content of a page for one of my university modules where we were required to write about something we were interested in, and unlikely to be picked by anybody else. I&#39;ve decided to stick it up here too, because why not?  &#60;br/&#62;
I had originally intended for this to be a list of some of my favourite indie games, but it quickly spiralled into just being about FTL. (Still might do that list later though)&#60;/p&#62;

&#60;h2 id=&#34;ftl:-faster-than-light&#34;&#62; FTL: Faster Than Light&#60;/h2&#62;
&#60;p&#62;&#60;img src=&#34;images/FTL.png&#34; alt=&#34;I should probably have put out those fires...&#34; loading=&#34;lazy&#34; /&#62; &#60;em&#62;Genre: indie, rogue-like, strategy&#60;/em&#62;&#60;/p&#62;

&#60;p&#62;FTL was a first in several ways for me. It was my first PC game (Now the only platform I play on), my first indie game (Now the vast majority of games that I play), and the first game I ever chose to buy myself, instead of having it bought for me. As a result, it&#39;s probably not possible for me to talk about it without looking through rose-tinted glasses to some extent, so take my opinion with a grain of salt.&#60;/p&#62;

&#60;p&#62;You play as the captain of a ship, belonging to the federation. You must manage your crew and energy usage and make decisions on how to survive throughout your journey and help defend the federation against the rebels.&#60;/p&#62;

&#60;p&#62;FTL is a &#34;rougelike&#34; game, meaning on each playthrough you start from scratch. Weak and with little to defend yourself, you must upgrade your ship and take on new crewmembers to hope to survive the many dangers you find as you explore the universe. With a wide range of weapons, from laser machine guns that take time to start up but are deadly once unleashed, to fire beams to kill your enemy ship&#39;s crew while leaving their ship (mostly) intact, and systems like hacking to take over a ship&#39;s navigation or teleporters to form boarding crews, there are many ways to play the game. Unfortunately for you, enemy ships also have access to the same arsenal of systems, and they aren&#39;t willing to go down without a fight.&#60;/p&#62;

&#60;p&#62;The game also has an &#60;a href=&#34;https://benprunty.bandcamp.com/album/ftl&#34;&#62;amazing soundtrack&#60;/a&#62; (+&#60;a href=&#34;https://benprunty.bandcamp.com/album/ftl-advanced-edition-soundtrack&#34;&#62;advanced edition soundtrack&#60;/a&#62;) by Ben Prunty, which perfectly fits the atmosphere of the game. It really wouldn&#39;t be the same without this great music.&#60;/p&#62;

&#60;p&#62;To make each run more different, the game also has unlockable ships (8 ships with 3 variants, and 2 more hidden ships with 2 variants each, for a total of a lot of ships), offering several different playstyles and extra challenges.&#60;/p&#62;

&#60;h3 id=&#34;choices&#34;&#62; Choices&#60;/h3&#62;
&#60;p&#62;&#60;img src=&#34;images/FTLChoice.jpg&#34; alt=&#34;Choices in FTL&#34; loading=&#34;lazy&#34; /&#62; &#60;em&#62;Extra options you have access to are highlighted in blue&#60;/em&#62;&#60;/p&#62;

&#60;p&#62;Another one of my favourite things about FTL is the choices it gives you. As an example:&#60;/p&#62;

&#60;p&#62;&#60;em&#62;&#34;You arrive at the distress beacon near a small asteroid belt and find a ship with pirate markings partially crushed between two large rocks. It must have been illegally mining the belt without proper equipment.&#34;&#60;/em&#62;  &#60;br/&#62;
Your choices to respond to this are:  &#60;br/&#62;
&#60;em&#62;&#34;Try to dislodge the pirates by shooting at the rocks.&#34;&#60;/em&#62; - Will you damage their ship by doing this? What if they think you&#39;re trying to attack them, or since they&#39;re pirates, decide to attack you anyway? However, they may also reward you for your assistance.  &#60;br/&#62;
&#60;em&#62;&#34;Destroy and loot the ship. They&#39;re just pirates.&#34;&#60;/em&#62; - You might get some scrap (The game&#39;s currency) from destroying them, but what if they have friends around that see you?  &#60;br/&#62;
However, if you have a beam weapon or beam drone, you can &#60;em&#62;&#34;(Beam Weapon) Carefully cut the ship out.&#34;&#60;/em&#62; - Guaranteed to work, and you&#39;ll get your scrap reward, however it requires having specific equipment on your ship.&#60;/p&#62;

&#60;p&#62;This is just one single simple event that you can come across in your exploration, and even it has complexity in its choices. There never is a perfect choice, and you can only guess at what the outcome of your actions will be.&#60;/p&#62;

&#60;p&#62;The game costs &#163;7, and &#60;a href=&#34;https://steamdb.info/app/212680/&#34;&#62;regularly goes on sale&#60;/a&#62; for the incredibly low price of &#163;1.74 - well worth the hundreds of hours of fun I&#39;ve gotten from this game (Note: At the time of writing, it is 75% off on steam!). As a warning though - FTL is hard. You&#39;ll die. A lot. Easy mode is a must when starting out, and I&#39;m still not convinced hard mode is actually beatable.  &#60;br/&#62;
&#60;a href=&#34;https://store.steampowered.com/app/212680/FTL_Faster_Than_Light/&#34;&#62;Steam&#60;/a&#62;  &#60;br/&#62;
&#60;a href=&#34;https://www.gog.com/game/faster_than_light&#34;&#62;GOG&#60;/a&#62; (Although the Steam version is also DRM free)  &#60;br/&#62;
&#60;a href=&#34;https://www.humblebundle.com/store/ftl-faster-than-light&#34;&#62;Humble&#60;/a&#62;  &#60;br/&#62;
And even &#60;a href=&#34;https://apps.apple.com/us/app/ftl-faster-than-light/id833951143&#34;&#62;iPad&#60;/a&#62;, although if you buy it here you&#39;ll miss out on what I&#39;m next to talk about...&#60;/p&#62;

&#60;h2 id=&#34;ftl:-multiverse&#34;&#62; FTL: Multiverse&#60;/h2&#62;
&#60;p&#62;&#60;img src=&#34;images/Multiverse.png&#34; alt=&#34;FTL: Multiverse Mod&#34; loading=&#34;lazy&#34; /&#62;&#60;/p&#62;

&#60;p&#62;Finally, the game has some amazing mods, particularly &#60;a href=&#34;https://www.subsetgames.com/forum/viewtopic.php?t=35332&#34;&#62;FTL: Multiverse&#60;/a&#62;. (The base game is good enough that I put over 100 hours into the vanilla game before looking at mods, but I recommend you try some out eventually). It essentially acts as a sequel, building significantly on the vanilla game - everything from significantly expanding the base game&#39;s atmospheric world building, to completely overhauling many mechanics of the base game and adding a &#60;strong&#62;&#60;em&#62;lot&#60;/em&#62;&#60;/strong&#62; of new content, and &#60;a href=&#34;https://www.youtube.com/playlist?list=PLXARrpodicQsHXiZoecojFMsoXvrTN1Hv&#34;&#62;20 new great music tracks&#60;/a&#62; to the vanilla&#39;s already stellar soundtrack. It essentially overhauls, expands, or refurbishes nearly every aspect of the game, whether it&#39;s ships, crew, events, weapons, etc. while still feeling balanced, and retaining what made the original game so great.&#60;/p&#62;

&#60;p&#62;The mod released in 2019, 7 years after the game released, and is still under active development, being on version 5.0 at the time of writing, with 5.1 set to release a few weeks from now, bringing a new mechanic, questline and sector. Multiverse is seriously one of my favourite mods I have ever played, and I love it.&#60;/p&#62;

&#60;h3 id=&#34;conclusion:-what-was-this-blog-post?&#34;&#62; Conclusion: What was this blog post?&#60;/h3&#62;
&#60;p&#62;Very rambly. Next blog post will probably be on something completely different, possibly how I&#39;m making this blog? Probably equally rambly though.&#60;/p&#62;


</content>
<author>
<name>James McKee</name>
</author>
<category term="faster-than-light"/>
<category term="gaming"/>
<category term="indie-games"/>
<summary type="html">
I ramble about a game I like for too long
</summary>
</entry>

<entry>
<title type="html">I kinda like JavaScript</title>
<link href="https://mck.is/blog/2022/i-kinda-like-javascript/index.html" rel="alternate" type="text/html" title="I kinda like JavaScript"/>
<published>2022-01-25T14:59:00Z</published>
<updated>2022-01-25T14:59:00Z</updated>
<id>https://mck.is/blog/2022/i-kinda-like-javascript/index.html</id>
<content type="html" xml:base="https://mck.is/blog/2022/i-kinda-like-javascript/index.html">
&#60;p&#62;Recently, as part of one of my university modules, I had to go and learn javascript.  &#60;br/&#62;
Going in, I had been dreading the prospect - Over the years I had built up a pretty negative image of javascript in my head.&#60;/p&#62;

&#60;p&#62;I&#39;d heard a lot about its oddities and weird behaviour over the years, and reading about NPM&#39;s many security issues and vulnerable packages over the years from the perspective of an outsider didn&#39;t exactly inspire me with confidence.&#60;/p&#62;

&#60;p&#62;Even after starting, I felt as if my worries were confirmed. Coming from having previously worked with C# and Java, it was a bigger change than I was expecting - Where were the types, why was everything &#60;code&#62;var&#60;/code&#62;? Semi-colons are optional? Why does everything seem to be &#60;code&#62;async&#60;/code&#62;?&#60;/p&#62;

&#60;p&#62;But after a while of pushing through these difficulties, it&#39;s really grown on me! My biggest initial hurdle - the dynamic typing - has now become one of my favourite things about it from the amount of flexibility it provides. It&#39;s also less different than I thought it was - the syntax is mostly familiar to me, as opposed to other languages like Python&#39;s whitespace-dependant syntax.&#60;/p&#62;

&#60;p&#62;It&#39;s also nice to have small things like template strings again, having loved string interpolation in C# then missing it when using Java.  &#60;br/&#62;
JSON is also entirely new to me, and so far I like it! It&#39;s a nicely human-readable way of storing data, and I significantly prefer it to the extreme verbosity of XML.  &#60;br/&#62;
Destructuring assignments also seems like a very useful feature to have, and I&#39;m looking forward to seeing what else javascript has to offer.&#60;/p&#62;

&#60;p&#62;All that said however, I&#39;ve really only just started using it. It&#39;s very possible my opinion on it will change after I begin to get fed up with its quirks a few months from now. I&#39;m just happy that I was wrong in my initial impression.&#60;/p&#62;

&#60;br/&#62;
&#60;p&#62;Finally - there&#39;s people reading this? That was unexpected! I was fully prepared for nobody to ever read anything I posted, so the fact that my first post received a few replies was a bit of a shock. Please, expect nothing high-quality out of this blog. Posts will be irregular and on whatever topic I feel like writing about. I have no experience with doing this sort of thing, I just thought it might be a neat idea.&#60;/p&#62;


</content>
<author>
<name>James McKee</name>
</author>
<category term="javascript"/>
<category term="programming"/>
<summary type="html">
... And I wasn't really expecting to.
</summary>
</entry>

<entry>
<title type="html">Hello World!</title>
<link href="https://mck.is/blog/2022/hello-world/index.html" rel="alternate" type="text/html" title="Hello World!"/>
<published>2022-01-23T00:00:00Z</published>
<updated>2022-01-23T00:00:00Z</updated>
<id>https://mck.is/blog/2022/hello-world/index.html</id>
<content type="html" xml:base="https://mck.is/blog/2022/hello-world/index.html">
&#60;p&#62;Hello world! This is just a short blog post to say that I&#39;m starting to make some blog posts.&#60;/p&#62;

&#60;p&#62;If you poke around the site, you&#39;ll very quickly realise how unfinished most of it is - however I&#39;ve now got a working setup that allows me to make and post blog posts, so I&#39;m starting that now. (I&#39;ll talk about how I&#39;m doing it in some of my later posts)&#60;/p&#62;

&#60;p&#62;I&#39;ve got some ideas in mind for what I&#39;ll be putting here, so hopefully I&#39;ll be able to get a few more of these out in the coming weeks!&#60;/p&#62;


</content>
<author>
<name>James McKee</name>
</author>
<category term="hello world"/>
<category term="about the blog"/>
<summary type="html">
What is this blog?
</summary>
</entry>

<entry>
<title type="html">Title</title>
<link href="https://mck.is/example.html" rel="alternate" type="text/html" title="Title"/>
<published>2021-12-28T20:27:00Z</published>
<updated>2021-12-29T00:00:00Z</updated>
<id>https://mck.is/example.html</id>
<content type="html" xml:base="https://mck.is/example.html">
&#60;p&#62;This page is a demonstration of the elements that can be formatted using Simple.css. Each section includes a code block on how to include it in your site&#8217;s design.&#60;/p&#62;

&#60;p&#62;This may be a little basic for some people, but I wanted to barrier for entry to be as low as possible for this project.&#60;/p&#62;

&#60;h2 id=&#34;basic-typography&#34;&#62; Basic Typography&#60;/h2&#62;
&#60;p&#62;All the typography of Simple.css uses &#60;code&#62;rem&#60;/code&#62; for sizing. This means that accessibility is maintained for those who change their browser font size. The &#60;code&#62;body&#60;/code&#62; element has a size of &#60;code&#62;1.15rem&#60;/code&#62; which makes all the standard font sizes slightly larger. This equates to &#60;code&#62;18.4px&#60;/code&#62; for paragraph text, instead of the standard &#60;code&#62;16px&#60;/code&#62;.&#60;/p&#62;

&#60;p&#62;The heading elements also have an increased top margin in order to break blocks of text up better.&#60;/p&#62;

&#60;h1 id=&#34;heading-1-code2.8rem/code&#34;&#62;Heading 1 &#60;code&#62;2.8rem&#60;/code&#62;&#60;/h1&#62;
&#60;h2 id=&#34;heading-2-code2.25rem/code&#34;&#62;Heading 2 &#60;code&#62;2.25rem&#60;/code&#62;&#60;/h2&#62;
&#60;h3 id=&#34;heading-3-code1.8rem/code&#34;&#62;Heading 3 &#60;code&#62;1.8rem&#60;/code&#62;&#60;/h3&#62;
&#60;h4 id=&#34;heading-4-code1.44rem/code&#34;&#62;Heading 4 &#60;code&#62;1.44rem&#60;/code&#62;&#60;/h4&#62;
&#60;h5 id=&#34;heading-5-code1.15rem/code&#34;&#62;Heading 5 &#60;code&#62;1.15rem&#60;/code&#62;&#60;/h5&#62;
&#60;h6 id=&#34;heading-6-code.92rem/code&#34;&#62;Heading 6 &#60;code&#62;.92rem&#60;/code&#62;&#60;/h6&#62;

&#60;p&#62;&#60;pre&#62;&#60;code&#62;&#38;#60;h2&#38;#62;This is a H2 header&#38;#60;h2&#38;#62;

&#38;#60;p&#38;#62;This is some paragraph text.&#38;#60;/p&#38;#62; &#60;/code&#62;&#60;/pre&#62;&#60;/p&#62;

&#60;h2 id=&#34;links&#34;&#62; Links&#60;/h2&#62;
&#60;p&#62;Links are formatted very simply on Simple.css (shock horror). They use the accent CSS variable and are underlined. There is a :hover effect that removes the underline. Here is an &#60;a href=&#34;https://example.com&#34; title=&#34;Alt text&#34;&#62;example link&#60;/a&#62;.&#60;/p&#62;

&#60;h2 id=&#34;other-typography-elements&#34;&#62; Other typography elements&#60;/h2&#62;
&#60;p&#62;There are a number of other typography elements that you can use with Simple.css. Some of the common ones are:&#60;/p&#62;

&#60;ul&#62;
	&#60;li&#62;All the standard stuff, like &#60;strong&#62;bold&#60;/strong&#62;, &#60;em&#62;italic&#60;/em&#62; and &#60;strong&#62;&#60;em&#62;both&#60;/em&#62;&#60;/strong&#62;.&#60;/li&#62;
 	&#60;li&#62;Adding &#60;code&#62;inline code&#60;/code&#62; using the &#60;code&#62;code&#60;/code&#62; element.&#60;/li&#62;
&#60;/ul&#62;

&#60;h1 id=&#34;images&#34;&#62; Images&#60;/h1&#62;
&#60;p&#62;In Simple.css, images within the &#60;code&#62;main&#60;/code&#62; element are always full width and have rounded edges to them. The &#60;code&#62;figcaption&#60;/code&#62; element is also formatted in Simple.css. Here are examples of images with and without a caption:&#60;/p&#62;

&#60;p&#62;&#60;img src=&#34;https://simplecss.org/assets/images/dog-ipad.jpg&#34; alt=&#34;Dog with a tablet&#34; loading=&#34;lazy&#34; /&#62;&#60;/p&#62;

&#60;p&#62;&#60;img src=&#34;https://simplecss.org/assets/images/goose.jpg&#34; alt=&#34;A black swan&#34; loading=&#34;lazy&#34; /&#62;&#60;/p&#62;


</content>
<author>
<name>James McKee</name>
</author>
<category term="example"/>
<category term="tags"/>
<category term="blog post"/>
<summary type="html">
Short description follows
</summary>
</entry>
</feed>